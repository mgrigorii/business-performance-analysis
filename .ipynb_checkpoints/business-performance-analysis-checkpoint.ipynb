{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business performance analysis \n",
    "We will calculate such indicators as: Conversion, bounce, retention, LVT, ROI, CAC and build charts to make it easier to analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Loading data and preparing it for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>Channel</th>\n",
       "      <th>costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>113.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>78.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt   Channel  costs\n",
       "0  2019-05-01  FaceBoom  113.3\n",
       "1  2019-05-02  FaceBoom   78.1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import visit data\n",
    "visits = pd.read_csv('data/costs_info_short.csv')\n",
    "visits.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>channel</th>\n",
       "      <th>costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>113.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt   channel  costs\n",
       "0  2019-05-01  FaceBoom  113.3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename table columns\n",
    "visits = visits.rename(columns={'User Id': 'user_id',\n",
    "                        'Region': 'region',\n",
    "                        'Device': 'device',\n",
    "                        'Channel': 'channel',\n",
    "                        'Session Start': 'session_start',\n",
    "                        'Session End': 'session_end'\n",
    "                       })\n",
    "visits.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Id</th>\n",
       "      <th>Event Dt</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188246423999</td>\n",
       "      <td>2019-05-01 23:09:52</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174361394180</td>\n",
       "      <td>2019-05-01 12:24:04</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        User Id             Event Dt  Revenue\n",
       "0  188246423999  2019-05-01 23:09:52     4.99\n",
       "1  174361394180  2019-05-01 12:24:04     4.99"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import order data\n",
    "orders = pd.read_csv('data/orders_info_short.csv')\n",
    "orders.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>event_dt</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188246423999</td>\n",
       "      <td>2019-05-01 23:09:52</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id             event_dt  revenue\n",
       "0  188246423999  2019-05-01 23:09:52     4.99"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename table columns\n",
    "orders = orders.rename(columns={'User Id': 'user_id',\n",
    "                        'Event Dt': 'event_dt',\n",
    "                        'Revenue': 'revenue'\n",
    "                       })\n",
    "orders.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>Channel</th>\n",
       "      <th>costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>113.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>78.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt   Channel  costs\n",
       "0  2019-05-01  FaceBoom  113.3\n",
       "1  2019-05-02  FaceBoom   78.1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cost data\n",
    "costs = pd.read_csv('data/costs_info_short.csv')\n",
    "costs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>channel</th>\n",
       "      <th>costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>113.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt   channel  costs\n",
       "0  2019-05-01  FaceBoom  113.3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename table columns\n",
    "costs = costs.rename(columns={'Channel': 'channel'\n",
    "                       })\n",
    "costs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates в visits: 0\n",
      "Number of duplicates в orders: 0\n",
      "Number of duplicates в costs: 0\n"
     ]
    }
   ],
   "source": [
    "# check data for duplicates\n",
    "print('Number of duplicates в visits:', visits.duplicated().sum())\n",
    "print('Number of duplicates в orders:', orders.duplicated().sum())\n",
    "print('Number of duplicates в costs:', costs.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1800 entries, 0 to 1799\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   dt       1800 non-null   object \n",
      " 1   channel  1800 non-null   object \n",
      " 2   costs    1800 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 42.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# chcecking for gaps\n",
    "visits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40212 entries, 0 to 40211\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   user_id   40212 non-null  int64  \n",
      " 1   event_dt  40212 non-null  object \n",
      " 2   revenue   40212 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 942.6+ KB\n"
     ]
    }
   ],
   "source": [
    "orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1800 entries, 0 to 1799\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   dt       1800 non-null   object \n",
      " 1   channel  1800 non-null   object \n",
      " 2   costs    1800 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 42.3+ KB\n"
     ]
    }
   ],
   "source": [
    "costs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- no duplicates were found in the datasets,\n",
    "- the number of records in all datasets is the same\n",
    "- no passes found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - we will set functions for calculating and analyzing LTV, ROI, retention and conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create user profiles\n",
    "\n",
    "def get_profiles(sessions, orders, ad_costs):\n",
    "    # Step 1. Pass data on advertising costs to the profile calculation function (ad_costs frame)\n",
    "    \n",
    "    # sort sessions by user id and date so that first works\n",
    "    # find the first values for the user parameters - we will consider them the main ones \n",
    "    profiles = (sessions.sort_values(by = ['user_id', 'session_start'])           \n",
    "                        .groupby('user_id').agg({'session_start' : 'first',       \n",
    "                                                 'channel': 'first',\n",
    "                                                 'device': 'first',\n",
    "                                                 'region': 'first'})                                 \n",
    "                        .rename(columns = {'session_start' : 'first_ts'})  \n",
    "                        .reset_index()  # return all data from the index to the columns                                           \n",
    "               )\n",
    "    # determine the date of the first visit\n",
    "    # and the beginning of the month of the first visit - we will need them for cohort analysis\n",
    "    profiles['dt'] = profiles['first_ts'].dt.date                                 \n",
    "    profiles['month'] = profiles['first_ts'].astype('datetime64[M]')     \n",
    "    \n",
    "    # add a sign of paying users\n",
    "    profiles['payer'] = profiles['user_id'].isin(orders['user_id'].unique())   \n",
    "            \n",
    "    # Step 2. Add the number of attracted users to the data on advertising costs\n",
    "    new_users = profiles.groupby(['dt', 'channel']).agg({'user_id': 'nunique'}).rename(columns = {'user_id': 'unique_users'}).reset_index()\n",
    "    ad_costs = ad_costs.merge(new_users, on = ['dt', 'channel'], how = 'left')\n",
    "    \n",
    "    # Step 3. Find the average user acquisition cost\n",
    "    ad_costs['acquisition_cost'] = ad_costs['costs'] / ad_costs['unique_users']\n",
    "    \n",
    "    # Step 4. Attach data to user profiles with information about the average acquisition cost per day of user acquisition from the desired source\n",
    "    profiles = profiles.merge(ad_costs[['dt', 'channel', 'acquisition_cost']], on = ['dt', 'channel'], how = 'left')\n",
    "    profiles['acquisition_cost'] = profiles['acquisition_cost'].fillna(0) # organic users will cost 0\n",
    "    \n",
    "    return profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate retention\n",
    "\n",
    "def get_retention(\n",
    "    profiles,\n",
    "    sessions,\n",
    "    observation_date,\n",
    "    horizon_days,\n",
    "    dimensions=[],\n",
    "    ignore_horizon=False,\n",
    "):\n",
    "\n",
    "    # add the payer column to the passed dimensions list\n",
    "    dimensions = ['payer'] + dimensions\n",
    "\n",
    "    # exclude users who did not \"survive\" to the analysis horizon\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - timedelta(\n",
    "            days=horizon_days - 1\n",
    "        )\n",
    "    result_raw = profiles.query('dt <= @last_suitable_acquisition_date')\n",
    "\n",
    "    # collect \"raw\" data to calculate retention\n",
    "    result_raw = result_raw.merge(\n",
    "        sessions[['user_id', 'session_start']], on='user_id', how='left'\n",
    "    )\n",
    "    result_raw['lifetime'] = (\n",
    "        result_raw['session_start'] - result_raw['first_ts']\n",
    "    ).dt.days\n",
    "\n",
    "    # function for grouping the table according to the desired features\n",
    "    def group_by_dimensions(df, dims, horizon_days):\n",
    "        result = df.pivot_table(\n",
    "            index=dims, columns='lifetime', values='user_id', aggfunc='nunique'\n",
    "        )\n",
    "        cohort_sizes = (\n",
    "            df.groupby(dims)\n",
    "            .agg({'user_id': 'nunique'})\n",
    "            .rename(columns={'user_id': 'cohort_size'})\n",
    "        )\n",
    "        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)\n",
    "        result = result.div(result['cohort_size'], axis=0)\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]\n",
    "        result['cohort_size'] = cohort_sizes\n",
    "        return result\n",
    "\n",
    "    # get the retention table\n",
    "    result_grouped = group_by_dimensions(result_raw, dimensions, horizon_days)\n",
    "\n",
    "    # get a table of retention dynamics\n",
    "    result_in_time = group_by_dimensions(\n",
    "        result_raw, dimensions + ['dt'], horizon_days\n",
    "    )\n",
    "\n",
    "    # return both tables and raw data\n",
    "    return result_raw, result_grouped, result_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating conversion\n",
    "\n",
    "def get_conversion(\n",
    "    profiles,\n",
    "    purchases,\n",
    "    observation_date,\n",
    "    horizon_days,\n",
    "    dimensions=[],\n",
    "    ignore_horizon=False,\n",
    "):\n",
    "\n",
    "    # exclude users who did not \"survive\" to the analysis horizon\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - timedelta(\n",
    "            days=horizon_days - 1\n",
    "        )\n",
    "    result_raw = profiles.query('dt <= @last_suitable_acquisition_date')\n",
    "\n",
    "    # determine the date and time of the first purchase for each user\n",
    "    first_purchases = (\n",
    "        purchases.sort_values(by=['user_id', 'event_dt'])\n",
    "        .groupby('user_id')\n",
    "        .agg({'event_dt': 'first'})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # add purchase data to profiles\n",
    "    result_raw = result_raw.merge(\n",
    "        first_purchases[['user_id', 'event_dt']], on='user_id', how='left'\n",
    "    )\n",
    "\n",
    "    # calculate lifetime for each purchase\n",
    "    result_raw['lifetime'] = (\n",
    "        result_raw['event_dt'] - result_raw['first_ts']\n",
    "    ).dt.days\n",
    "\n",
    "    # group by cohort if there is nothing in dimensions\n",
    "    if len(dimensions) == 0:\n",
    "        result_raw['cohort'] = 'All users' \n",
    "        dimensions = dimensions + ['cohort']\n",
    "\n",
    "    # function for grouping the table according to the desired features\n",
    "    def group_by_dimensions(df, dims, horizon_days):\n",
    "        result = df.pivot_table(\n",
    "            index=dims, columns='lifetime', values='user_id', aggfunc='nunique'\n",
    "        )\n",
    "        result = result.fillna(0).cumsum(axis = 1)\n",
    "        cohort_sizes = (\n",
    "            df.groupby(dims)\n",
    "            .agg({'user_id': 'nunique'})\n",
    "            .rename(columns={'user_id': 'cohort_size'})\n",
    "        )\n",
    "        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)\n",
    "        # divide each \"cell\" in the row by the size of the cohort\n",
    "        # and get the conversion rate\n",
    "        result = result.div(result['cohort_size'], axis=0)\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]\n",
    "        result['cohort_size'] = cohort_sizes\n",
    "        return result\n",
    "\n",
    "    # get the conversion table\n",
    "    result_grouped = group_by_dimensions(result_raw, dimensions, horizon_days)\n",
    "\n",
    "    # remove 'cohort' from dimensions for the conversion dynamics table\n",
    "    if 'cohort' in dimensions: \n",
    "        dimensions = []\n",
    "\n",
    "    # get a table of conversion dynamics\n",
    "    result_in_time = group_by_dimensions(\n",
    "        result_raw, dimensions + ['dt'], horizon_days\n",
    "    )\n",
    "\n",
    "    # return both tables and raw data\n",
    "    return result_raw, result_grouped, result_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating LTV and ROI\n",
    "\n",
    "def get_ltv(\n",
    "    profiles,\n",
    "    purchases,\n",
    "    observation_date,\n",
    "    horizon_days,\n",
    "    dimensions=[],\n",
    "    ignore_horizon=False,\n",
    "):\n",
    "\n",
    "    # exclude users who did not \"survive\" to the analysis horizon\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - timedelta(\n",
    "            days=horizon_days - 1\n",
    "        )\n",
    "    result_raw = profiles.query('dt <= @last_suitable_acquisition_date')\n",
    "    # add purchase data to profiles\n",
    "    result_raw = result_raw.merge(\n",
    "        purchases[['user_id', 'event_dt', 'revenue']], on='user_id', how='left'\n",
    "    )\n",
    "    # calculate the user's lifetime for each purchase\n",
    "    result_raw['lifetime'] = (\n",
    "        result_raw['event_dt'] - result_raw['first_ts']\n",
    "    ).dt.days\n",
    "    # group by cohort if there is nothing in dimensions\n",
    "    if len(dimensions) == 0:\n",
    "        result_raw['cohort'] = 'All users'\n",
    "        dimensions = dimensions + ['cohort']\n",
    "\n",
    "    # grouping function according to the desired features\n",
    "    def group_by_dimensions(df, dims, horizon_days):\n",
    "        # строим «треугольную» таблицу выручки\n",
    "        result = df.pivot_table(\n",
    "            index=dims, columns='lifetime', values='revenue', aggfunc='sum'\n",
    "        )\n",
    "        # находим сумму выручки с накоплением\n",
    "        result = result.fillna(0).cumsum(axis=1)\n",
    "        # calculate cohort sizes\n",
    "        cohort_sizes = (\n",
    "            df.groupby(dims)\n",
    "            .agg({'user_id': 'nunique'})\n",
    "            .rename(columns={'user_id': 'cohort_size'})\n",
    "        )\n",
    "        # combine cohort sizes and revenue table\n",
    "        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)\n",
    "        # calculate LTV: divide each \"cell\" in the row by the size of the cohort\n",
    "        result = result.div(result['cohort_size'], axis=0)\n",
    "        # exclude all lifetimes that exceed the analysis horizon\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]\n",
    "        # restore cohort sizes\n",
    "        result['cohort_size'] = cohort_sizes\n",
    "\n",
    "        # collect dataframe with user data and CAC values,\n",
    "        # adding parameters from dimensions\n",
    "        cac = df[['user_id', 'acquisition_cost'] + dims].drop_duplicates()\n",
    "\n",
    "        # calculate the average CAC by parameters from dimensions\n",
    "        cac = (\n",
    "            cac.groupby(dims)\n",
    "            .agg({'acquisition_cost': 'mean'})\n",
    "            .rename(columns={'acquisition_cost': 'cac'})\n",
    "        )\n",
    "\n",
    "        # calculate ROI: divide LTV by CAC\n",
    "        roi = result.div(cac['cac'], axis=0)\n",
    "\n",
    "        # remove rows with infinite ROI\n",
    "        roi = roi[~roi['cohort_size'].isin([np.inf])]\n",
    "\n",
    "        # restore cohort sizes in the ROI table\n",
    "        roi['cohort_size'] = cohort_sizes\n",
    "\n",
    "        # add CAC to ROI table\n",
    "        roi['cac'] = cac['cac']\n",
    "\n",
    "        # in the final table we leave the sizes of cohorts, CAC\n",
    "        # and ROI in lifetimes that do not exceed the analysis horizon\n",
    "        roi = roi[['cohort_size', 'cac'] + list(range(horizon_days))]\n",
    "\n",
    "        # return LTV and ROI tables\n",
    "        return result, roi\n",
    "\n",
    "    # get LTV and ROI tables\n",
    "    result_grouped, roi_grouped = group_by_dimensions(\n",
    "        result_raw, dimensions, horizon_days\n",
    "    )\n",
    "\n",
    "    # for dynamics tables remove 'cohort' from dimensions\n",
    "    if 'cohort' in dimensions:\n",
    "        dimensions = []\n",
    "\n",
    "    # get tables of LTV and ROI dynamics\n",
    "    result_in_time, roi_in_time = group_by_dimensions(\n",
    "        result_raw, dimensions + ['dt'], horizon_days\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        result_raw,      # raw data\n",
    "        result_grouped,  # LTV table\n",
    "        result_in_time,  # LTV dynamics table\n",
    "        roi_grouped,     # ROI table\n",
    "        roi_in_time,     # table of ROI dynamics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to smooth the frame\n",
    "\n",
    "def filter_data(df, window):\n",
    "    # apply a moving average for each column\n",
    "    for column in df.columns.values:\n",
    "        df[column] = df[column].rolling(window).mean() \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to visualize retention\n",
    "\n",
    "def plot_retention(retention, retention_history, horizon, window=7):\n",
    "\n",
    "    # set the grid size for charts\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # exclude cohort sizes and first day retention\n",
    "    retention = retention.drop(columns=['cohort_size', 0])\n",
    "    # leave only the desired lifetime in the dynamics table\n",
    "    retention_history = retention_history.drop(columns=['cohort_size'])[\n",
    "        [horizon - 1]\n",
    "    ]\n",
    "\n",
    "    # if there is only payer in the indexes of the hold table,\n",
    "    # add the second feature - cohort\n",
    "    if retention.index.nlevels == 1:\n",
    "        retention['cohort'] = 'All users'\n",
    "        retention = retention.reset_index().set_index(['cohort', 'payer'])\n",
    "\n",
    "    # in the graph table - two columns and two rows, four cells\n",
    "    # in the first we build retention curves for paying users\n",
    "    ax1 = plt.subplot(2, 2, 1)\n",
    "    retention.query('payer == True').droplevel('payer').T.plot(\n",
    "        grid=True, ax=ax1\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.xlabel('Lifetime')\n",
    "    plt.title('Retention of paying users')\n",
    "\n",
    "    # in the second cell we build non-paying retention curves\n",
    "    # vertical axis - from the graph from the first cell\n",
    "    ax2 = plt.subplot(2, 2, 2, sharey=ax1)\n",
    "    retention.query('payer == False').droplevel('payer').T.plot(\n",
    "        grid=True, ax=ax2\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.xlabel('Lifetime')\n",
    "    plt.title('Retention of non-paying users')\n",
    "\n",
    "    # in the third cell - the dynamics of retention of paying\n",
    "    ax3 = plt.subplot(2, 2, 3)\n",
    "    # get the column names for the pivot table\n",
    "    columns = [\n",
    "        name\n",
    "        for name in retention_history.index.names\n",
    "        if name not in ['dt', 'payer']\n",
    "    ]\n",
    "    # filter the data and build a graph\n",
    "    filtered_data = retention_history.query('payer == True').pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax3)\n",
    "    plt.xlabel('Engagement date')\n",
    "    plt.title(\n",
    "        'Dynamics of retention of paying users for day {}'.format(\n",
    "            horizon\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # in the fourth cell - the dynamics of retention of non-paying\n",
    "    ax4 = plt.subplot(2, 2, 4, sharey=ax3)\n",
    "    # filter the data and build a graph\n",
    "    filtered_data = retention_history.query('payer == False').pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax4)\n",
    "    plt.xlabel('Engagement date')\n",
    "    plt.title(\n",
    "        'Dynamics of retention of non-paying users for day {}'.format(\n",
    "            horizon\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to visualize the conversion\n",
    "\n",
    "def plot_conversion(conversion, conversion_history, horizon, window=7):\n",
    "\n",
    "    # set the grid size for charts\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # exclude cohort sizes\n",
    "    conversion = conversion.drop(columns=['cohort_size'])\n",
    "    # leave only the desired lifetime in the dynamics table\n",
    "    conversion_history = conversion_history.drop(columns=['cohort_size'])[\n",
    "        [horizon - 1]\n",
    "    ]\n",
    "\n",
    "    # first chart - conversion curves\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    conversion.T.plot(grid=True, ax=ax1)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Engagement date')\n",
    "    plt.title('User conversion')\n",
    "\n",
    "    # second graph - conversion dynamics\n",
    "    ax2 = plt.subplot(1, 2, 2, sharey=ax1)\n",
    "    columns = [\n",
    "        # all index columns except date will become pivot table columns\n",
    "        name for name in conversion_history.index.names if name not in ['dt']\n",
    "    ]\n",
    "    filtered_data = conversion_history.pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax2)\n",
    "    plt.xlabel('Engagement date')\n",
    "    plt.title('Dynamics of user conversion for day {}'.format(horizon))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to visualize LTV and ROI\n",
    "\n",
    "def plot_ltv_roi(ltv, ltv_history, roi, roi_history, horizon, window=7):\n",
    "\n",
    "    # set the grid for drawing charts\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    # exclude cohort sizes from table ltv\n",
    "    ltv = ltv.drop(columns=['cohort_size'])\n",
    "    # leave only the desired lifetime in the ltv dynamics table\n",
    "    ltv_history = ltv_history.drop(columns=['cohort_size'])[[horizon - 1]]\n",
    "\n",
    "    # write the cost of attraction in a separate frame\n",
    "    cac_history = roi_history[['cac']]\n",
    "\n",
    "    # exclude cohort sizes and cac from table roi\n",
    "    roi = roi.drop(columns=['cohort_size', 'cac'])\n",
    "    # in the dynamics table roi leave only the desired lifetime\n",
    "    roi_history = roi_history.drop(columns=['cohort_size', 'cac'])[\n",
    "        [horizon - 1]\n",
    "    ]\n",
    "\n",
    "   # first graph - ltv curves\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    ltv.T.plot(grid=True, ax=ax1)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Lifetime')\n",
    "    plt.title('LTV')\n",
    "\n",
    "    # second graph - ltv dynamics\n",
    "    ax2 = plt.subplot(2, 3, 2, sharey=ax1)\n",
    "    # all index columns except date will become pivot table columns\n",
    "    columns = [name for name in ltv_history.index.names if name not in ['dt']]\n",
    "    filtered_data = ltv_history.pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax2)\n",
    "    plt.xlabel('Engagement date')\n",
    "    plt.title('User LTV dynamics on the {} day'.format(horizon))\n",
    "\n",
    "    # the third graph is the dynamics of cac\n",
    "    ax3 = plt.subplot(2, 3, 3, sharey=ax1)\n",
    "    # all index columns except date will become pivot table columns\n",
    "    columns = [name for name in cac_history.index.names if name not in ['dt']]\n",
    "    filtered_data = cac_history.pivot_table(\n",
    "        index='dt', columns=columns, values='cac', aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax3)\n",
    "    plt.xlabel('Engagement date')\n",
    "    plt.title('User Acquisition Cost Dynamics')\n",
    "\n",
    "    # fourth graph - roi curves\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    roi.T.plot(grid=True, ax=ax4)\n",
    "    plt.axhline(y=1, color='red', linestyle='--', label='Payback level')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Lifetime')\n",
    "    plt.title('ROI')\n",
    "\n",
    "    # the fifth graph is the dynamics of roi\n",
    "    ax5 = plt.subplot(2, 3, 5, sharey=ax4)\n",
    "    # all index columns except date will become pivot table columns\n",
    "    columns = [name for name in roi_history.index.names if name not in ['dt']]\n",
    "    filtered_data = roi_history.pivot_table(\n",
    "        index='dt', columns=columns, values=horizon - 1, aggfunc='mean'\n",
    "    )\n",
    "    filter_data(filtered_data, window).plot(grid=True, ax=ax5)\n",
    "    plt.axhline(y=1, color='red', linestyle='--', label='Payback level')\n",
    "    plt.xlabel('Engagement date')\n",
    "    plt.title('User ROI dynamics on the {} day'.format(horizon))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Exploratory data analysis (EDA)\n",
    "\n",
    "Let's build user profiles. Determine the minimum and maximum date for attracting users.\n",
    "\n",
    "will answer questions\n",
    "\n",
    "- What countries do visitors come from? Which countries have the most paying users?\n",
    "- What devices do they use? What devices do paying users visit most often?\n",
    "- What advertising channels were used to attract users? Which channels bring in the most paying users?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>channel</th>\n",
       "      <th>costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>113.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>78.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>85.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>136.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>FaceBoom</td>\n",
       "      <td>122.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt   channel  costs\n",
       "0  2019-05-01  FaceBoom  113.3\n",
       "1  2019-05-02  FaceBoom   78.1\n",
       "2  2019-05-03  FaceBoom   85.8\n",
       "3  2019-05-04  FaceBoom  136.4\n",
       "4  2019-05-05  FaceBoom  122.1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visits.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'session_start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'session_start'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# converting time data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m visits[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_start\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mvisits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msession_start\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      3\u001b[0m orders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_dt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(orders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_dt\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m costs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(costs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'session_start'"
     ]
    }
   ],
   "source": [
    "# converting time data\n",
    "visits['session_start'] = pd.to_datetime(visits['session_start'])\n",
    "orders['event_dt'] = pd.to_datetime(orders['event_dt'])\n",
    "costs['dt'] = pd.to_datetime(costs['dt']).dt.date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_date = datetime(2019, 11, 1).date()  # moment of analysis\n",
    "horizon_days = 14  # analysis horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user profiles\n",
    "profiles = get_profiles(visits, orders, costs)\n",
    "profiles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What countries do visitors come from? \n",
    "# Which countries have the most paying users?\n",
    "\n",
    "profiles.query('payer == True').pivot_table(\n",
    "    index='dt',        # dates of first visits\n",
    "    columns='region',  # transition country\n",
    "    values='user_id',  # User IDs\n",
    "    aggfunc='nunique'  # counting unique values\n",
    ").plot(figsize=(15, 5), grid=True)\n",
    "plt.xlabel('Engagement date')\n",
    "plt.title('Arrival of users by country')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, 6 times more customers come from the USA than from other countries, which is understandable, the US population is much larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What devices do they use? \n",
    "# What devices do paying users visit most often?\n",
    "\n",
    "profiles.query('payer == True').pivot_table(\n",
    "    index='dt',        # dates of first visits\n",
    "    columns='device',  # transition device\n",
    "    values='user_id',  # User IDs\n",
    "    aggfunc='nunique'  # counting unique values\n",
    ").plot(figsize=(15, 5), grid=True)\n",
    "\n",
    "plt.xlabel('Engagement date')\n",
    "plt.title('User Devices')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most referrals from iphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What advertising channels did you use to attract users? \n",
    "# Which channels bring in the most paying users?\n",
    "\n",
    "profiles.query('payer == True').pivot_table(\n",
    "    index='dt',         # dates of first visits\n",
    "    columns='channel',  # referral sources\n",
    "    values='user_id',   # User IDs\n",
    "    aggfunc='nunique'   # counting unique values\n",
    ").plot(figsize=(15, 5), grid=True)\n",
    "\n",
    "plt.xlabel('Engagement date')\n",
    "plt.title('Acquisition channels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdNoSense Leading Customer Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share of paying users by country\n",
    "user_by_region = pd.DataFrame(profiles.pivot_table(index='region', values='user_id', aggfunc='count'))\n",
    "user_by_region.columns = ['user_cout']\n",
    "user_by_region.reset_index()\n",
    "\n",
    "\n",
    "paing_user_by_region = pd.DataFrame(profiles.query('payer == True').pivot_table(index='region', values='user_id', aggfunc='count'))\n",
    "paing_user_by_region.columns = ['paing_user_cout']\n",
    "paing_user_by_region.reset_index()\n",
    "\n",
    "tab = pd.merge(user_by_region, paing_user_by_region, 'left', on = 'region')\n",
    "tab['part'] = (tab['paing_user_cout'] / tab['user_cout']) * 100\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share of paying users by device\n",
    "\n",
    "user_by_device = pd.DataFrame(profiles.pivot_table(index='device', values='user_id', aggfunc='count'))\n",
    "user_by_device.columns = ['user_cout']\n",
    "user_by_device.reset_index()\n",
    "\n",
    "\n",
    "paing_user_by_device = pd.DataFrame(profiles.query('payer == True').pivot_table(index='device', values='user_id', aggfunc='count'))\n",
    "paing_user_by_device.columns = ['paing_user_cout']\n",
    "paing_user_by_device.reset_index()\n",
    "\n",
    "user_part_device = pd.merge(user_by_device, paing_user_by_device, 'left', on = 'device')\n",
    "user_part_device['part'] = (user_part_device['paing_user_cout'] / user_part_device['user_cout']) * 100\n",
    "user_part_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share of paying users by acquisition channels\n",
    "\n",
    "user_by_channel = pd.DataFrame(profiles.pivot_table(index='channel', values='user_id', aggfunc='count'))\n",
    "user_by_channel.columns = ['user_cout']\n",
    "user_by_channel.reset_index()\n",
    "\n",
    "\n",
    "paing_user_by_channel = pd.DataFrame(profiles.query('payer == True').pivot_table(index='channel', values='user_id', aggfunc='count'))\n",
    "paing_user_by_channel.columns = ['paing_user_cout']\n",
    "paing_user_by_channel.reset_index()\n",
    "\n",
    "user_part_channel = pd.merge(user_by_channel, paing_user_by_channel, 'left', on = 'channel')\n",
    "user_part_channel['part'] = (user_part_channel['paing_user_cout'] / user_part_channel['user_cout']) * 100\n",
    "user_part_channel.sort_values(by='part',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum engagement date\n",
    "max_acquisition_date = profiles.reset_index()['dt'].max()\n",
    "\n",
    "# minimum engagement date\n",
    "min_acquisition_date = profiles.reset_index()['dt'].min()\n",
    "\n",
    "print('Maximum engagement date:', max_acquisition_date)\n",
    "print('Minimum engagement date:', min_acquisition_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Marketing\n",
    "\n",
    "Find out:\n",
    "- How much money have you spent? Total / per source / by time\n",
    "- How much did it cost on average to acquire one customer from each source?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
